{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3853,"status":"ok","timestamp":1720229850708,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"},"user_tz":-420},"id":"lnH3NTN03ZZ6","outputId":"575af7e3-ee70-4fef-ce2a-c2e78968dac7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"62MK1VZA3abV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720229161163,"user_tz":-420,"elapsed":77293,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}},"outputId":"672b3351-65ae-4b3d-a26e-79e14a0486f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Collecting datasets\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Collecting requests>=2.32.2 (from datasets)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"]}],"source":["%pip install transformers\n","%pip install torch\n","%pip install pandas\n","%pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UO-uHlxHOeyY"},"outputs":[],"source":["from datasets import load_dataset\n","dataset = load_dataset(\"imdb\", split='train[:1000]')\n","test_data = load_dataset(\"imdb\", split='test[:200]')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer, AutoModel\n","\n","# Load model directly\n","tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n","\n","def preprocess(data):\n","    inputs = tokenizer(data['text'], padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n","    labels = torch.tensor(data['label'])\n","    return inputs, labels\n","\n","train_inputs, train_labels = preprocess(dataset)\n","test_inputs, test_labels = preprocess(test_data)\n","\n","class TransformerClassifier(nn.Module):\n","    def __init__(self, num_labels):\n","        super(TransformerClassifier, self).__init__()\n","        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n","        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.last_hidden_state[:, 0]  # Take the CLS token output\n","        return self.classifier(pooled_output)\n","\n","model = TransformerClassifier(num_labels=2)\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n","train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","\n","test_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n","test_dataloader = DataLoader(test_dataset, batch_size=8)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","criterion = nn.CrossEntropyLoss()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","for epoch in range(10):\n","    model.train()\n","    total_loss = 0\n","    for batch in train_dataloader:\n","        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_dataloader)}\")\n","\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for batch in test_dataloader:\n","        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n","        outputs = model(input_ids, attention_mask)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = correct / total\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"el9GD-WvVr4l","executionInfo":{"status":"ok","timestamp":1720190723126,"user_tz":-420,"elapsed":66597,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}},"outputId":"cb1880a2-201e-469b-869a-41ba3bcc2fcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.02079708417505026\n","Epoch 2, Loss: 0.0016345793046057225\n","Epoch 3, Loss: 0.0009931858177296817\n","Epoch 4, Loss: 0.0007268807697109878\n","Epoch 5, Loss: 0.0005843806103803217\n","Epoch 6, Loss: 0.0005018800520338118\n","Epoch 7, Loss: 0.0004361661018338054\n","Epoch 8, Loss: 0.0003964835526421666\n","Epoch 9, Loss: 0.0003597970535047352\n","Epoch 10, Loss: 0.00033509825682267547\n","Accuracy: 100.00%\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"FEwxFwCEYN37"}},{"cell_type":"code","source":["!pip install --upgrade transformers accelerate\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BO1R85ZtrdTn","executionInfo":{"status":"ok","timestamp":1720229719378,"user_tz":-420,"elapsed":6754,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}},"outputId":"f104837e-547e-4806-a997-8851ac5f7691"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.3)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoTokenizer\n","\n","# Tải dữ liệu\n","train_data = load_dataset(\"imdb\", split='train[:1000]')\n","test_data = load_dataset(\"imdb\", split='test[:200]')\n","\n","# Khởi tạo tokenizer\n","bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n","\n","# Tokenize dữ liệu\n","def tokenize_data(data, tokenizer):\n","    return data.map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length'), batched=True)\n","\n","train_data_bert = tokenize_data(train_data, bert_tokenizer)\n","test_data_bert = tokenize_data(test_data, bert_tokenizer)\n","train_data_roberta = tokenize_data(train_data, roberta_tokenizer)\n","test_data_roberta = tokenize_data(test_data, roberta_tokenizer)\n","\n","# Đảm bảo dữ liệu đã được đặt lại dạng PyTorch tensor\n","train_data_bert.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_data_bert.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","train_data_roberta.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_data_roberta.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"],"metadata":{"id":"zgDnTi_Bos7l","executionInfo":{"status":"ok","timestamp":1720230080363,"user_tz":-420,"elapsed":7671,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","\n","class IMDbDataset(Dataset):\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","\n","    def __getitem__(self, idx):\n","        item = {\n","            'input_ids': self.dataset['input_ids'][idx],\n","            'attention_mask': self.dataset['attention_mask'][idx],\n","            'labels': self.dataset['label'][idx]\n","        }\n","        return item\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","train_dataset_bert = IMDbDataset(train_data_bert)\n","test_dataset_bert = IMDbDataset(test_data_bert)\n","train_dataset_roberta = IMDbDataset(train_data_roberta)\n","test_dataset_roberta = IMDbDataset(test_data_roberta)\n"],"metadata":{"id":"fCKn3DY2shqJ","executionInfo":{"status":"ok","timestamp":1720230174358,"user_tz":-420,"elapsed":557,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","import numpy as np\n"],"metadata":{"id":"kKqrITdLzcHA","executionInfo":{"status":"ok","timestamp":1720231776359,"user_tz":-420,"elapsed":908,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Hàm tính toán độ chính xác\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = np.argmax(pred.predictions, axis=-1)\n","    acc = accuracy_score(labels, preds)\n","    return {'accuracy': acc}"],"metadata":{"id":"9DePcKytxoKt","executionInfo":{"status":"ok","timestamp":1720231778968,"user_tz":-420,"elapsed":3,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n","\n","# Khởi tạo mô hình BERT\n","bert_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","\n","# Định nghĩa Trainer\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n",")\n","\n","trainer_bert = Trainer(\n","    model=bert_model,\n","    args=training_args,\n","    train_dataset=train_dataset_bert,\n","    eval_dataset=test_dataset_bert,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer_bert.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"tr_Fdcg0p0TZ","executionInfo":{"status":"ok","timestamp":1720232088503,"user_tz":-420,"elapsed":305647,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}},"outputId":"a96300fd-4b76-492f-ce3e-a5271b76d3bd"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [189/189 05:03, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.001425</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.000721</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.000600</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=189, training_loss=0.01980894583242911, metrics={'train_runtime': 304.4982, 'train_samples_per_second': 9.852, 'train_steps_per_second': 0.621, 'total_flos': 789333166080000.0, 'train_loss': 0.01980894583242911, 'epoch': 3.0})"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# Khởi tạo mô hình RoBERTa\n","roberta_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n","\n","trainer_roberta = Trainer(\n","    model=roberta_model,\n","    args=training_args,\n","    train_dataset=train_dataset_roberta,\n","    eval_dataset=test_dataset_roberta,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer_roberta.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"16HK4w9Wt6eq","executionInfo":{"status":"ok","timestamp":1720232422489,"user_tz":-420,"elapsed":308343,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}},"outputId":"1b32e6ab-9708-4847-b504-13b2f6be0da2"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [189/189 05:05, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.000212</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.000137</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.000121</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=189, training_loss=0.02813162374748755, metrics={'train_runtime': 306.8951, 'train_samples_per_second': 9.775, 'train_steps_per_second': 0.616, 'total_flos': 789333166080000.0, 'train_loss': 0.02813162374748755, 'epoch': 3.0})"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# Đánh giá mô hình BERT\n","bert_results = trainer_bert.evaluate()\n","bert_accuracy = bert_results['eval_accuracy']\n","\n","# Đánh giá mô hình RoBERTa\n","roberta_results = trainer_roberta.evaluate()\n","roberta_accuracy = roberta_results['eval_accuracy']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":57},"id":"hwR0iXk3t-eu","executionInfo":{"status":"ok","timestamp":1720232436672,"user_tz":-420,"elapsed":12580,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}},"outputId":"babecd6c-f4df-418f-aa51-d93f6fa6a4dc"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13/13 00:05]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13/13 00:05]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["print(\"BERT:\", bert_results)\n","print(\"RoBERTa:\", roberta_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vo62Tp3whKs","executionInfo":{"status":"ok","timestamp":1720233206608,"user_tz":-420,"elapsed":1301,"user":{"displayName":"Tuấn Nguyễn Duy","userId":"13781921621114420072"}},"outputId":"9c64bc86-6b90-49b1-d471-3c79016e0733"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT: {'eval_loss': 0.0006004861206747591, 'eval_accuracy': 1.0, 'eval_runtime': 6.0315, 'eval_samples_per_second': 33.159, 'eval_steps_per_second': 2.155, 'epoch': 3.0}\n","RoBERTa: {'eval_loss': 0.00012144901847932488, 'eval_accuracy': 1.0, 'eval_runtime': 6.412, 'eval_samples_per_second': 31.192, 'eval_steps_per_second': 2.027, 'epoch': 3.0}\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyP++kXqSfNPW/tziYdFaEIV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}